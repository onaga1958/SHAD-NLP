{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Домашнее задание №1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Тема: Языковое моделирование и определение языка.\n",
    "\n",
    "\n",
    "**Выдана**:   14 сентября 2017\n",
    "\n",
    "**Дедлайн**:   <font color='red'>9:00 утра 28 сентября 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания $-$ отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев $-$ тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 3). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение семинаристов в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе Вам предстоит реализовать n-грамную языковую модель с несколькими видами сглаживания:\n",
    "- Add-one smoothing\n",
    "- Stupid backoff\n",
    "- Interpolation smoothing\n",
    "- Kneser-Ney smoothing\n",
    "\n",
    "Вы обучите ее на готовых корпусах, оцените качество и проведете ряд экспериментов. Во второй части задания Вы примените реализованную модель (но с буквенными n-граммами) к задаче распознавания языка. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Цель языкового моделирования заключается в том, чтобы присвоить некоторые вероятности предложениям. Задача состоит в подсчете вероятности $P(W) = P(w_1, \\dots, w_n)$ или $P(w_n \\mid w_1, \\dots, w_{n-1})$. Модель, умеющая вычислять хотя бы одну из этих двух вероятностей, называется **языковой моделью** (LM от Language Model).\n",
    "\n",
    "Согласно **цепному правилу** (chain rule):\n",
    "\n",
    "$$P(X_1, \\dots, X_n) = P(X_1)P(X_2 \\mid X_1)\\dots P(X_n \\mid X_1, \\dots, X_{n-1}).$$ \n",
    "\n",
    "Также мы знаем, что\n",
    "\n",
    "$$\n",
    "    P(X_n \\mid X_1, \\dots, X_{n-1}) = \\frac{P(X_1, \\dots, X_n)}{P(X_1, \\dots, X_{n-1})},\n",
    "$$\n",
    "\n",
    "следовательно, для того чтобы оценить $P(X_n \\mid X_1, \\dots, X_{n-1})$ нужно посчитать $P(X_1, \\dots, X_n)$ и $P(X_1, \\dots, X_{n-1})$. Но эти вероятности будут чрезвычайно малы, если мы возьмем большое $n$, так множество предложений из $n$ слов растет экспоненциально. Для упрощения применим **марковское предположение**: \n",
    "\n",
    "$$P(X_n \\mid X_1, \\dots, X_{n-1}) = P(X_n \\mid X_{n - k + 1}, \\dots, X_{n-1})$$\n",
    "\n",
    "для некоторого фиксированного (небольшого) $k$. Это предположение говорит о том, что $X_{n}$ не зависит от $X_{1}, \\dots, X_{n - k}$, то есть на следующее слово влияет лишь контекст из предыдущих $k - 1$ слова. Таким образом, мы получаем финальную вероятность:\n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_i P(w_i \\mid w_{i-k+1}, \\dots, w_{i - 1}).\n",
    "$$\n",
    "\n",
    "Далее для краткости будем обозначать $w_{i-k}^i := w_{i-k}, \\dots, w_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Хранилище n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для начала выполним вспомогательную работу. Следуйте комментариям, чтобы написать NGramStorage с удобным интерфейсом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NGramStorage:\n",
    "    \"\"\"Storage for ngrams' frequencies.\n",
    "    \n",
    "    Args:\n",
    "        sents (list[list[str]]): List of sentences from which ngram\n",
    "            frequencies are extracted.\n",
    "        max_n (int): Upper bound of the length of ngrams.\n",
    "            For instance if max_n = 2, then storage will store\n",
    "            0, 1, 2-grams.\n",
    "            \n",
    "    Attributes:\n",
    "        max_n (Readonly(int)): Upper bound of the length of ngrams.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, sents=[], max_n=0):\n",
    "        self.__max_n = max_n\n",
    "        self.__ngrams = {i: Counter() for i in range(self.__max_n + 1)}\n",
    "        # self._ngrams[K] should have the following interface:\n",
    "        # self._ngrams[K][(w_1, ..., w_K)] = number of times w_1, ..., w_K occured in words\n",
    "        # self._ngrams[0][()] = number of all words\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        for sent in sents:\n",
    "            for i in range(self.__max_n + 1):\n",
    "                self.__ngrams[i].update([tuple(sent[j:j+i])\n",
    "                                         for j in range(len(sent) - i + 1)])\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def add_unk_token(self):\n",
    "        \"\"\"Add UNK token to 1-grams.\"\"\"\n",
    "        # In order to avoid zero probabilites \n",
    "        if self.__max_n == 0 or ('UNK',) in self.__ngrams[1]:\n",
    "            return\n",
    "        self.__ngrams[0][()] += 1\n",
    "        self.__ngrams[1][('UNK', )] = 1\n",
    "        \n",
    "    @property\n",
    "    def max_n(self):\n",
    "        \"\"\"Get max_n\"\"\"\n",
    "        return self.__max_n\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Get dictionary of k-gram frequencies.\n",
    "        \n",
    "        Args:\n",
    "            k (int): length of returning ngrams' frequencies.\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary (in fact Counter) of k-gram frequencies.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(k, int):\n",
    "            raise TypeError('k (length of ngrams) must be an integer!')\n",
    "        if k > self.__max_n:\n",
    "            raise ValueError('k (length of ngrams) must be less or equal to the maximal length!')\n",
    "        return self.__ngrams[k]\n",
    "    \n",
    "    def __call__(self, ngram):\n",
    "        \"\"\"Return frequency of a given ngram.\n",
    "        \n",
    "        Args:\n",
    "            ngram (tuple): ngram for which frequency should be computed.\n",
    "            \n",
    "        Returns:\n",
    "            Frequency (int) of a given ngram.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(ngram, tuple):\n",
    "            raise TypeError('ngram must be a tuple!')\n",
    "        if len(ngram) > self.__max_n:\n",
    "            raise ValueError('length of ngram must be less or equal to the maximal length!')\n",
    "        if len(ngram) == 1 and ngram not in self.__ngrams[1]:\n",
    "            return self.__ngrams[1][('UNK', )]\n",
    "        return self.__ngrams[len(ngram)][ngram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Скачайте brown корпус, обучите модель и протестируйте на нескольких примерах последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment next row and download brown corpus\n",
    "# nltk.download()\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем все к нижнему регистру и добавим токены начала и конца предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sentences = 57340\n",
      "Number of train sentences = 45872\n",
      "Number of test sentences = 11468\n"
     ]
    }
   ],
   "source": [
    "all_sents = list(brown.sents())\n",
    "all_sents = [['__begin__'] + [word.lower() for word in sent] + ['__end__']\n",
    "             for sent in all_sents]\n",
    "random.shuffle(all_sents)\n",
    "print('Number of all sentences = {}'.format(len(all_sents)))\n",
    "train_sents = all_sents[:int(0.8 * len(all_sents))]\n",
    "test_sents = all_sents[int(0.8 * len(all_sents)):]\n",
    "print('Number of train sentences = {}'.format(len(train_sents)))\n",
    "print('Number of test sentences = {}'.format(len(test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create storage of 0, 1, 2, 3-grams\n",
    "storage = NGramStorage(train_sents, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1359\n",
      "3349\n",
      "27\n",
      "0\n",
      "1066913\n"
     ]
    }
   ],
   "source": [
    "# It's time to test your code\n",
    "print(storage(('to', 'be')))\n",
    "print(storage(('or',)))\n",
    "print(storage(('not', 'to', 'be')))\n",
    "print(storage(('somethingweird',)))\n",
    "print(storage(()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для численного измерения качества языковой модели определим **перплексию**:\n",
    "\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1, \\dots, w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_i P(w_i \\mid w_{i - k}, \\dots, w_{i - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "Важно, что минимизация перплексии эквивалентна максимизации правдоподобия модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте функцию по подсчету перплексии. Обратите внимание, что перплексия по корпусу равна произведению вероятностей **всех** предложений в степени $-\\frac1N$, где $N -$ суммарная длина всех предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$10^{-50}$ слишком большое значение. Из-за этого перплексия существенно занижается, так как вероятность многих предложений получается меньше $10^{-50}$, и в случае нулевой вероятности не видно \"взрыва\", хотя по-хорошему перплексия должна уходить в бесконечноть. С одной стороны \"взрывы\" могут пугать, с а другой они ярко демонстрируют недостатки и проблемы некоторых методов. Поэтому взял $10^{-100}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perplexity(estimator, sents):\n",
    "    '''Estimate perplexity of the sequence of words using prob_estimator.'''\n",
    "    ### YOUR CODE HERE\n",
    "    # Avoid log(0) by replacing zero by 10 ** (-50).\n",
    "    perp = 0\n",
    "    N = 0\n",
    "    for sent in sents:\n",
    "        perp += np.log(estimator.prob(sent) or 10 ** (-100))\n",
    "        N += len(sent)\n",
    "        \n",
    "    perp /= -N\n",
    "    perp = np.e ** perp\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка вероятностей n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Первый и простейший способ оценки вероятностей N-грам следующий:\n",
    "\n",
    "$$\n",
    "    \\hat P_{S}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N)}{c(w_1^{N-1})}.\n",
    "$$\n",
    "\n",
    "где $c(w_1^N)$ — это число последовательностей $w_1, \\dots, w_N$ в корпусе, $S$ символизирует Straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StraightforwardProbabilityEstimator:\n",
    "    \"\"\"Class for simplest probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = c(context + word) / c(context), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage):\n",
    "        self.__storage = storage\n",
    "        # Adding UNK token to avoid zero probabilities\n",
    "        self.__storage.add_unk_token()\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('context must be a tuple of strings!')\n",
    "        for w in context:\n",
    "            if not isinstance(w, str):\n",
    "                raise TypeError('context must be a tuple of strings!') \n",
    "\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        # Avoiding 0 / 0.\n",
    "        if context_counts == 0:\n",
    "            return 0\n",
    "        return phrase_counts / context_counts\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 25010.83835997765\n",
      "0.001273767145243197\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "simple_estimator = StraightforwardProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(simple_estimator, test_sents)))\n",
    "print(simple_estimator.prob('to be'.split()))\n",
    "print(simple_estimator.prob('to be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь как раз можем наблюдать \"взрыв\" перплексии, который происходит из-за того, что вероятности многих предложений ранва 0. Наш эстиматор весьма примитивен: он не использует никаких сглаживаний, а значит, если какой-то триграмы в корпусе не было, то вероятность всего предложения равна 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Посчитаем перплексию униграмной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 887.8432346986323\n"
     ]
    }
   ],
   "source": [
    "uni_storage = NGramStorage(train_sents, 1)\n",
    "uni_simple_estimator = StraightforwardProbabilityEstimator(uni_storage)\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(uni_simple_estimator, test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() 1066914\n",
      "('to',) 20922\n",
      "('to', 'be') 1359\n",
      "('to', 'be', 'or') 1\n",
      "('be', 'or', 'not') 0\n",
      "('or', 'not', 'to') 2\n",
      "('not', 'to', 'be') 27\n"
     ]
    }
   ],
   "source": [
    "sent = 'to be or not to be'.split()\n",
    "for i in range(len(sent) + 1):\n",
    "    trigram = tuple(sent[max(0, i - 3):i])\n",
    "    print(trigram, storage(tuple(sent[max(0, i - 3):i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Какие выводы можно сделать? Почему $P(\\text{To be or not to be}) = 0$, хотя мы и добавили UNK токен?  \n",
    "**A:** Две триграмы, учавствующие в подсчете вероятности, не встречались в корпусе, поэтому данный эстиматор счиает, что вероятность этого предложнения равна 0. С таким эстиматором при не очень большом корпусе (наш случай) вообще вероятность предложений часто всего будет равна 0, ведь стоит поменять, например, порядок слов в триграме, и она уже может не встретится в таком виде в корпусе и занулит вероятность.\n",
    "\n",
    "**Q:** Почему перплексия униграмной модели меньше, чем триграмной?  \n",
    "**A:** В общем-то проблема триграмной модели описана выше. Униграмная модель в этом плане гораздо более мягкая, и, чтобы вероятность предложения не была равна 0, нужно лишь чтобы все слова из него встречались в корпусе. А раз вероятности предложений в униграмной модели больше, значит перплексия меньше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Add-one smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Простейший вид сглаживания — **сглаживание Лапласа**. Чтобы избавиться от нулевых вероятностей $P(w_{N} \\mid w_1^{N - 1})$, будем использовать формулу:\n",
    "\n",
    "$$\n",
    "    \\hat P_{AOS}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N) + \\delta}{c(w_1^{N-1}) + \\delta V},\n",
    "$$\n",
    "\n",
    "где $V$ — это размер словаря, а $\\delta$ — некоторая фиксированная константа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте класс, осуществляющий сглаживание Лапласа. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LaplaceProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = (c(context + word) + delta) / (c(context) + delta * V), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus,\n",
    "    delta - some constant,\n",
    "    V - number of different words in corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): Smoothing parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('context must be a tuple!')\n",
    "            \n",
    "        ### YOUR CODE HERE\n",
    "        for w in context:\n",
    "            if not isinstance(w, str):\n",
    "                raise TypeError('context must be a tuple of strings!') \n",
    "\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "\n",
    "        return (phrase_counts + self.__delta)/(context_counts + self.__delta * len(self.__storage[1]))\n",
    "        \n",
    "        ### END YOUR CODE\n",
    "            \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Подберите наилучший параметр $\\delta$ для данного корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим вначале порядок, а потом подберем уже конкретный множитель. Заодно для наглядности можно построить график. На графиках отображена зависимость перплексии от логарифма $\\delta$. Собственно, выбираем ту $\\delta$, которой соответствует минимальная перплексия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perplexity(delta):\n",
    "    laplace_estimator = LaplaceProbabilityEstimator(storage, delta)\n",
    "    return perplexity(laplace_estimator, test_sents)\n",
    "\n",
    "\n",
    "def get_best_delta_from_possible_deltas(possible_deltas):\n",
    "    perplexities = [get_perplexity(d) for d in possible_deltas]\n",
    "    plt.plot(np.log10(possible_deltas), perplexities)\n",
    "    best_index = np.argmin(perplexities)\n",
    "    return possible_deltas[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAFkCAYAAABmeZIKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D8tZNrnKF6bjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38d13cd940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rough_estimate = get_best_delta_from_possible_deltas([10 ** i for i in range(-6,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если захотите позапускать, но не хотите ждать, лучше уменьшите число вариантов. $20$ вполне достаточно, чтобы получился красивый график :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFkCAYAAABvkjJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38d3e18c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_detailed_variants = 20\n",
    "variants = np.linspace(np.log10(rough_estimate) - 1,\n",
    "                       np.log10(rough_estimate) + 1,\n",
    "                       number_of_detailed_variants)\n",
    "variants = [10 ** var for var in variants]\n",
    "best_delta = get_best_delta_from_possible_deltas(variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_delta =  0.000695192796178\n",
      "Laplace estimator perplexity = 3763.8240385962504\n",
      "0.00127182878593\n"
     ]
    }
   ],
   "source": [
    "# Try to find out best delta parameter. We will not provide you any strater code.\n",
    "### YOUR CODE HERE\n",
    "print('best_delta = ', best_delta)\n",
    "### END YOUR CODE\n",
    "\n",
    "# Initialize estimator\n",
    "laplace_estimator = LaplaceProbabilityEstimator(storage, best_delta)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Laplace estimator perplexity = {}'.format(perplexity(laplace_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, действительно есть некоторое оптимальное дельта. Правда результат даже с ним все равно не очень. Но, конечно, лучше, чем в случае простого эстиматора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stupid backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Идея **простого отката** довольно понятна. Если у нас есть достаточно информцаии для подсчета вероятности $k$-грам, то будем использовать $k$-грамы. Иначе будем использовать вероятности $(k-1)$-грам с некоторым множителем, например, $0.4$, и так далее. К сожалению, в данном случае мы получим не вероятностное распределение, но в большинстве задач это не имеет принципиального значения. Если это все же важно, то необходимо подобрать множитель соответствующим образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте класс, симулирующий сглаживание простым откатом. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StupidBackoffProbabilityEstimator:\n",
    "    \"\"\"Class for stupid backoff probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        P'(word | context),                  if  P'(word | context) > 0;\n",
    "        P'(word | context[1:]) * multiplier, if  P'(word | context) == 0\n",
    "                                             and P'(word | context[1:]) > 0;\n",
    "        ...\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        multiplier (float): Multiplier which is used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, multiplier=0.1):\n",
    "        self.__base_estimator = base_estimator\n",
    "        self.__mult = multiplier\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        context = self.__base_estimator.cut_context(context)\n",
    "        prob = self.__base_estimator(word, context)\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob if prob != 0 else self.__mult*self(word, context[1:]) \n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stupid backoff estimator perplexity = 397.04601821612346\n",
      "0.001273767145243197\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "sbackoff_estimator = StupidBackoffProbabilityEstimator(simple_estimator, .4)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Stupid backoff estimator perplexity = {}'.format(perplexity(sbackoff_estimator, test_sents)))\n",
    "print(sbackoff_estimator.prob('to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Почему бессмысленно измерять перплексию в случае **Stupid backoff**?  \n",
    "**A:** Потому что то, что мы имеем на выходе, не является вероятностным распределением: сумма всех \"вероятностей\" не даст единицу, она будет больше. Поэтому естественно, что если подставить эти \"вероятности\" в формулу для перплексии, то мы получем заниженное значение. При чем её нельзя даже использовать для сравнения разных коэффициентов, потому что суммы вероятностей опять же будут отличаться.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Interpolation smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В данном случае идея сглаживания посредством **интерполяции** также крайне проста. Пусть у нас есть $N$-грамная модель. Заведем вектор $\\bar\\lambda = (\\lambda_1, \\dots, \\lambda_N)$, такой, что $\\sum_i\\lambda_i = 1$ и $\\lambda_i \\geq 0$. Тогда\n",
    "\n",
    "$$\n",
    "    \\hat P_{IS}(w_{N} \\mid w_1^{N-1}) = \\sum_{i=1}^N \\lambda_i \\hat P_{S}(w_N \\mid w_{N-i+1}^{N-1}).\n",
    "$$\n",
    "\n",
    "Придумайте, как обойтись одним вектором $\\bar\\lambda$, т.е. пользоваться им как в случае контекста длины $N$, так и при контексте меньшей длины (например, в начале предложения). Если мы просто обрубим сумму, то у нас уже не будет вероятностное распределение, что, конечно же, плохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При длине контекста $len(c)$ меньшей $N$ оставим $len(c)$ последних $\\lambda$ и отнормируем их к $1$. В этом случае мы вновь получим на выходе вероятностное распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class InterpolationProbabilityEstimator:\n",
    "    \"\"\"Class for interpolation probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        lambda_N * P'(word | context) +\n",
    "        lambda_{N-1} * P'(word | context[1:]) +\n",
    "        ... +\n",
    "        lambda_1 * P'(word)\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        lambdas (np.array[float]): Lambdas which are used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, lambdas):\n",
    "        self.lambdas = list(reversed(lambdas))\n",
    "        self.__base_estimator = base_estimator\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        context = self.__base_estimator.cut_context(context)\n",
    "        probs = [self.__base_estimator(word, context[i:])\n",
    "                 for i in range(len(context) + 1)]\n",
    "            \n",
    "        lambdas = self.lambdas[:len(context) + 1]\n",
    "        prob = sum([p * lam for p, lam in zip(probs,\n",
    "                                              lambdas)])\n",
    "        prob /= sum(lambdas)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation estimator perplexity = 471.09793750275594\n",
      "0.00097884710234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize estimator\n",
    "interpol_estimator = InterpolationProbabilityEstimator(simple_estimator, np.array([0.2, 0.2, 0.6]))\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Interpolation estimator perplexity = {}'.format(perplexity(interpol_estimator, test_sents)))\n",
    "print(interpol_estimator.prob('to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, перплексия уже значительно лучше. Радует, что улучшения модели действительно работают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обучить значения параметров $\\lambda$ можно с помощью EM-алгоритма, но мы не будем этого здесь делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Идея данного сглаживания заключается в том, что словам, которые участвуют в большом количестве контекстов, присваиваются большие вероятности, а те, которые используются в паре-тройке контекстов, получают маленькие вероятности. Формулы приведены на слайде 37 лекции.\n",
    "Реализуйте данный подход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если использовать просто формулы с лекции, то все равно относительно часто вероятность предложений получается 0. <a href=\"https://web.stanford.edu/~jurafsky/slp3/4.pdf\">Вот здесь</a> для решения этой проблемы в оценке вероятности для униграм вводится еще одно константное небольшое слагаемое, отвечающее равномерному распределению. Естественно, для этого из первого слагаемого нужно немного вычесть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_endings(storage):\n",
    "    def _endings_for_ngrams(n, dictionary):\n",
    "        unique_endings = {}\n",
    "        for ngram in storage[n].keys():\n",
    "            key = ngram[:-1]\n",
    "            value = ngram[-1]\n",
    "            if unique_endings.get(key) is None:\n",
    "                unique_endings[key] = [value]\n",
    "            else:\n",
    "                unique_endings[key].append(value)\n",
    "\n",
    "        for key, value in unique_endings.items():\n",
    "            dictionary[key] = len(set(value))\n",
    "\n",
    "    result = {}\n",
    "    _endings_for_ngrams(2, result)\n",
    "    _endings_for_ngrams(3, result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_unique_beginnings(storage):\n",
    "    unique_beginnings = {}\n",
    "    for ngram in storage[2].keys():\n",
    "        key = ngram[1]\n",
    "        value = ngram[0]\n",
    "        if unique_beginnings.get(key) is None:\n",
    "            unique_beginnings[key] = [value]\n",
    "        else:\n",
    "            unique_beginnings[key].append(value)\n",
    "            \n",
    "    return {key: len(set(value))\n",
    "            for key, value in unique_beginnings.items()}\n",
    "\n",
    "\n",
    "def count_ngram_with_countinues(storage):\n",
    "    def _count_countinues(n, result):\n",
    "        for ngram, value in storage[n].items():\n",
    "            key = ngram[:-1]\n",
    "            if result.get(key) is None:\n",
    "                result[key] = value\n",
    "            else:\n",
    "                result[key] += value\n",
    "    result = {}\n",
    "    _count_countinues(2, result)\n",
    "    _count_countinues(3, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class KneserNeyProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = ...\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): KneserNey parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        self.__counted_endings = count_unique_endings(storage)\n",
    "        self.__counted_beginnings = count_unique_beginnings(storage)\n",
    "        self.__counted_ngram_with_countinues = count_ngram_with_countinues(storage)\n",
    "        # print(list(self.__counted_endings.items())[:100])\n",
    "        # print(list(self.__counted_beginnings.items())[:100])\n",
    "        # print(list(self.__counted_bigram_with_countinues.items())[:100])\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            context = context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        if len(context) > 0:\n",
    "            denominator = self.__counted_ngram_with_countinues.setdefault(context, 0)\n",
    "            if denominator == 0:\n",
    "                return self(word, context[1:])\n",
    "            unique_continued = self.__counted_endings.setdefault(context, 0)\n",
    "            return (max(self.__storage(context + (word,)) - self.__delta, 0) / denominator +\n",
    "                    self.__delta / denominator * unique_continued * self(word, context[1:]))\n",
    "        else:\n",
    "            uniform = self.__delta / self.__storage(())\n",
    "            unique_begin = self.__counted_beginnings.setdefault(word, 0)\n",
    "            return max(unique_begin - self.__delta, 0) / len(self.__storage[2]) + uniform\n",
    "        ### END YOUR CODE\n",
    "            \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KN estimator perplexity = 521.741439540655\n",
      "0.0007989387936916641\n",
      "8.197844594661268e-11\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "kn_estimator = KneserNeyProbabilityEstimator(storage)\n",
    "# Estimating perplexity\n",
    "print('KN estimator perplexity = {}'.format(perplexity(kn_estimator, test_sents)))\n",
    "print(kn_estimator.prob('to be'.split()))\n",
    "print(kn_estimator.prob('to be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь перплексия получилась чуть больше, чем в случае интерполяционного эстиматора, но разница не настолько велика, чтобы однозначно говорить о том, какой из этих методов лучше. Зато видно, что оба они значительно лучше более наивных методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Определение языка документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Постановка задачи:**  \n",
    "Одна из задач, которая может быть решена при помощи языковых моделей $-$ **определение языка документа**. Реализуйте два классификатора для определения языка документа:\n",
    "1. Наивный классификатор, который будет учитывать частоты символов и выбирать язык текста по признаку: распределение частот символов \"наиболее похоже\" на распределение частот символов в выбранном языке.\n",
    "2. Классификатор на основе языковых моделей. Сами придумайте, как он должен работать.  \n",
    "_Подсказка_: лучше считать n-грамы не по словам, а по символам.\n",
    "\n",
    "---\n",
    "\n",
    "**Как представлены данные:**  \n",
    "Во всех текстовых файлах на каждой строчке записано отдельное предложение.\n",
    "1. В папке _data_ находятся две папки: _full_ и _plain_. В _full_ находятся тексты в той форме, что они были взяты из сети, в _plain_ находятся те же самые тексты, но с них сначала была снята диакритика, а затем русский и греческий тексты были транслитерованы в английский.\n",
    "2. В каждой из папок _full_ и _plain_ находятся папки _train_ и _test_.\n",
    "3. В _train_ находятся файлы с текстами с говорящими именами, например, _ru.txt_, _en.txt_.\n",
    "4. В _test_ находятся файлы _1.txt_, _2.txt_, $\\dots$ в которых хранятся тексты, язык которых нужно определить. В этой же папке находится файл _ans.csv_, в котором вы можете найти правильные ответы и проверить, насколько хорошо сработали Ваши алгоритмы.\n",
    "\n",
    "---\n",
    "\n",
    "**Что нужно сделать:**  \n",
    "Напишите два своих классификатора (которые описаны в постановке задачи) и получите максимально возможное accuracy на test-сете. Разрешается использовать только _train_ для обучения.\n",
    "\n",
    "---\n",
    "\n",
    "**В данном задании мы не предоставляем стартового кода!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_file_names(path, extension='txt'):\n",
    "    return [file_name for file_name in os.listdir(path)\n",
    "            if file_name.split('.')[-1] == extension]\n",
    "\n",
    "def get_texts(dir_path, file_names, row=False):\n",
    "    def prepare_doc(name, row=False):\n",
    "        if row:\n",
    "            return open(dir_path + name, 'r').read().lower()\n",
    "        else:\n",
    "            return [['__begin__'] + list(word) + ['__end__']\n",
    "                    for word in open(dir_path + name, 'r').read().lower().split()]\n",
    "\n",
    "    return [prepare_doc(name, row)\n",
    "            for name in file_names]\n",
    "\n",
    "extension = 'txt'\n",
    "path_train = './plain/train/'\n",
    "path_test = './plain/test/'\n",
    "ans_file = 'ans.csv'\n",
    "\n",
    "doc_names_train = get_file_names(path_train)\n",
    "doc_names_test = list(sorted(get_file_names(path_test),\n",
    "                             key=lambda name: int(name.split('.')[0])))\n",
    "\n",
    "train = get_texts(path_train, doc_names_train)\n",
    "test = get_texts(path_test, doc_names_test)\n",
    "train_row = get_texts(path_train, doc_names_train, True)\n",
    "test_row = get_texts(path_test, doc_names_test, True)\n",
    "\n",
    "\n",
    "languages = [file_name.split('.')[0]\n",
    "             for file_name in doc_names_train]\n",
    "\n",
    "answers = pd.read_csv(path_test + ans_file, header=None).values.T[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как у меня работает наивный классификатор?  \n",
    "При обучении он составит Counter для каждого из языков.  \n",
    "При классификации он считает ошибку в виде суммы квадратов разностей частотов символов в посчитаных на этапе обучения Counter'ах и частот в Counter'е классифицируемого текста. Выбирать будем тот язык, ошибка для которого получилась наименьшей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    def __init__(self, train, languages):\n",
    "        self.languages = languages\n",
    "        self.counters = [Counter(text) for text in train]\n",
    "        for counter, text in zip(self.counters, train):\n",
    "            self._to_freq(counter, len(text))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _to_freq(counter, lenght):\n",
    "        for key in counter.keys():\n",
    "            counter[key] /= lenght\n",
    "            \n",
    "    @staticmethod\n",
    "    def _error(counter1, counter2):\n",
    "        error = 0\n",
    "        all_keys = set(list(counter1.keys()) + list(counter2.keys()))\n",
    "        for key in all_keys:\n",
    "            error += (counter1[key] - counter2[key])**2\n",
    "        return error\n",
    "            \n",
    "    def __call__(self, test):\n",
    "        test_counter = Counter(test)\n",
    "        self._to_freq(test_counter, len(test))\n",
    "        errors = [self._error(train_counter, test_counter)\n",
    "                  for train_counter in self.counters]\n",
    "        best_index = np.argmin(errors)\n",
    "        return self.languages[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = NaiveClassifier(train_row, languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(classifier, test_data, answers):\n",
    "    return len([1 for text, ans in zip(test_data, answers)\n",
    "                if classifier(text) == ans]) / len(answers)\n",
    "\n",
    "\n",
    "def print_mistakes(classifier, test_data, answers, print_limit=10):\n",
    "    mistakes = 0\n",
    "    for i, (text, ans) in enumerate(zip(test_row[:50], answers[:50])):\n",
    "        my_ans = classifier(text)\n",
    "        if my_ans != ans and mistakes < 10:\n",
    "            print(i, 'right: ', ans, 'my: ', my_ans)\n",
    "            mistakes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(classifier, test_row, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 right:  en my:  de\n"
     ]
    }
   ],
   "source": [
    "print_mistakes(classifier, test_row, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, такой, весьма простой, подход показал прекрасный результат: всего одна ошибка из 240 тестов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуем классификатор работающий на языковых моделях. Он с учетом уже разработанного функционала работает довольно просто.  \n",
    "На трейне инициализируем для каждого языка свою модель.  \n",
    "Классифицировать будем следующим образом: посчитаем перплексию на тестовом тексте для каждой из языковых моделей, инициализированных на стадии трейна, а затем выберем язык, которому соответствует наименьшая перплексия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LanguageModelClassifier:\n",
    "    def __init__(self, train, languages, model_class, gram_lenght=3):\n",
    "        self.languages = languages\n",
    "        self.models = [model_class(NGramStorage(text, gram_lenght))\n",
    "                       for text in train]\n",
    "        \n",
    "    def __call__(self, text):\n",
    "        perplexities = [perplexity(model, text) for model in self.models]\n",
    "        best_ind = np.argmin(perplexities)\n",
    "        return self.languages[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interpolation_model(storage):\n",
    "    simple_estimator = StraightforwardProbabilityEstimator(storage)\n",
    "    return InterpolationProbabilityEstimator(simple_estimator,\n",
    "                                             np.array([0.2, 0.2, 0.6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробудем взять для классификации две лучшие языковые модели: интерполяционную и Kneser Nay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это будет не быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_inter = LanguageModelClassifier(train, languages,\n",
    "                                           get_interpolation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(classifier_inter, test, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это тоже не быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_KN = LanguageModelClassifier(train, languages, KneserNeyProbabilityEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(classifier_KN, test, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случах классификатор отработал без ошибок. Зато работает эта прелесть существенно дольше, чем простой частотный классификатор, который показал почти идеальный результат. Так что если не нужен прям сверх точный результат, но зато нужна производительность, то стоит задуматься, прежде чем кидаться пилить языковую модель. В общем-то, как и везде, главное - подходить с умом к задаче :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
